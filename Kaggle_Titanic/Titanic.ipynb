{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "op = 0 # 0: Local, 1: Kaggle\n",
    "\n",
    "if not op: # Local\n",
    "    train_path = './data/train.csv'\n",
    "    test_path = './data/test.csv'\n",
    "    sub_path = './data/gender_submission.csv'\n",
    "    save_path = './data/submission.csv'\n",
    "else:  # Kaggle\n",
    "    train_path = '/kaggle/input/titanic/train.csv'\n",
    "    test_path = '/kaggle/input/titanic/test.csv'\n",
    "    sub_path = '/kaggle/input/titanic/gender_submission.csv'    \n",
    "    save_path = '/kaggle/working/submission.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "df_sub = pd.read_csv(sub_path)\n",
    "\n",
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Pclass           0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "=====================\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary columns\n",
    "df_train = df_train.drop(columns=['Name', 'Ticket'])\n",
    "df_test = df_test.drop(columns=['Name', 'Ticket'])\n",
    "\n",
    "# Check NaN\n",
    "print(df_train[df_test.columns].isnull().sum())\n",
    "print(\"=====================\")\n",
    "print(df_test[df_test.columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN list:  Age, Cabin, Fare, Embarked\n",
    "\n",
    "# Age\n",
    "def age_to_group(age):\n",
    "    if pd.isna(age):\n",
    "        return 7\n",
    "    elif age <= 10:\n",
    "        return 0\n",
    "    elif age <= 20:\n",
    "        return 1\n",
    "    elif age <= 30:\n",
    "        return 2\n",
    "    elif age <= 40:\n",
    "        return 3\n",
    "    elif age <= 50:\n",
    "        return 4\n",
    "    elif age <= 60:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "df_train['AgeGroup'] = df_train['Age'].apply(age_to_group)\n",
    "df_test['AgeGroup'] = df_test['Age'].apply(age_to_group)\n",
    "\n",
    "# Fare\n",
    "df_test['Fare'] = df_test['Fare'].fillna(df_test.groupby('Pclass')['Fare'].transform('mean'))\n",
    "\n",
    "# Embarked\n",
    "df_train['Embarked'] = df_train['Embarked'].fillna('N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "def data_encoding(df):\n",
    "    df['Sex'] = encoder.fit_transform(df['Sex'])\n",
    "    df['Embarked'] = encoder.fit_transform(df['Embarked'])\n",
    "    return df\n",
    "\n",
    "df_train = data_encoding(df_train)\n",
    "df_test = data_encoding(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['FamilySize'] = (df_train['SibSp'] + df_train['Parch']) **2\n",
    "df_test['FamilySize'] = (df_test['SibSp'] + df_test['Parch']) **2\n",
    "\n",
    "df_train['IsAlone'] = (df_train['FamilySize'] == 0).astype(int)\n",
    "df_test['IsAlone'] = (df_test['FamilySize'] == 0).astype(int)\n",
    "\n",
    "df_train['ClassByFare'] = (df_train['Fare'] / df_train['Pclass'])\n",
    "df_test['ClassByFare'] = (df_test['Fare'] / df_test['Pclass'])\n",
    "\n",
    "df_train['SexByEmbarked'] = (df_train['Sex'] + 1) * (df_train['Embarked'] + 1)\n",
    "df_test['SexByEmbarked'] = (df_test['Sex'] + 1) * (df_test['Embarked'] + 1)\n",
    "\n",
    "df_train['SexByIsAlone'] = (df_train['Sex'] + 1) * (df_train['IsAlone'] + 1)\n",
    "df_test['SexByIsAlone'] = (df_test['Sex'] + 1) * (df_test['IsAlone'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass              : 0.0843\n",
      "Sex                 : 0.1428\n",
      "FamilySize          : 0.0203\n",
      "IsAlone             : 0.0136\n",
      "ClassByFare         : 0.1481\n",
      "Fare                : 0.1369\n",
      "SexByEmbarked       : 0.1413\n",
      "SexByIsAlone        : 0.1076\n"
     ]
    }
   ],
   "source": [
    "# Select Feature\n",
    "feature_cols = ['Pclass', 'Sex', 'FamilySize', 'IsAlone', 'ClassByFare', 'Fare', 'SexByEmbarked', 'SexByIsAlone']\n",
    "df_train[feature_cols].head(10)\n",
    "\n",
    "# Check Feature importance\n",
    "importances = mutual_info_classif(df_train[feature_cols], df_train['Survived'])\n",
    "for col, imp in zip(feature_cols, importances):\n",
    "    print(f'{col:<20}: {imp:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Tuning - LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split input and target data\n",
    "X = df_train[feature_cols].to_numpy()\n",
    "y = df_train['Survived'].to_numpy()\n",
    "X_pred = df_test[feature_cols].to_numpy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8455056179775281\n",
      "0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    n_jobs=-1,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=300,\n",
    "    verbose = -1\n",
    ")\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "print(lgbm.score(X_train, y_train))\n",
    "print(lgbm.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 01:59:37,433] A new study created in memory with name: no-name-b9c81ac8-34a4-4051-b5c9-936451c25a6f\n",
      "[I 2025-04-06 01:59:39,544] Trial 0 finished with value: 0.8092398468394955 and parameters: {'learning_rate': 0.05882792871828515, 'n_estimators': 316, 'max_depth': 7, 'num_leaves': 62, 'min_child_samples': 18, 'subsample': 0.687970928123946, 'colsample_bytree': 0.6048445232853208, 'reg_alpha': 0.8999542808972761, 'reg_lambda': 0.6696781440492665}. Best is trial 0 with value: 0.8092398468394955.\n",
      "[I 2025-04-06 01:59:41,361] Trial 1 finished with value: 0.812591802146758 and parameters: {'learning_rate': 0.055217709892021224, 'n_estimators': 686, 'max_depth': 4, 'num_leaves': 60, 'min_child_samples': 82, 'subsample': 0.8978818803669101, 'colsample_bytree': 0.7145664856186515, 'reg_alpha': 0.11488146510133246, 'reg_lambda': 0.28150901883984303}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 01:59:43,516] Trial 2 finished with value: 0.8024919967359235 and parameters: {'learning_rate': 0.08842296914927081, 'n_estimators': 756, 'max_depth': 9, 'num_leaves': 65, 'min_child_samples': 51, 'subsample': 0.6918120055520415, 'colsample_bytree': 0.7206226401327585, 'reg_alpha': 0.7643030986911691, 'reg_lambda': 0.6996105096692926}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 01:59:45,466] Trial 3 finished with value: 0.783422258489737 and parameters: {'learning_rate': 0.007562900257262844, 'n_estimators': 794, 'max_depth': 3, 'num_leaves': 69, 'min_child_samples': 43, 'subsample': 0.7132969334556876, 'colsample_bytree': 0.9250233812605562, 'reg_alpha': 0.21119641167497538, 'reg_lambda': 0.06059222147692478}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 01:59:46,727] Trial 4 finished with value: 0.8002448057246877 and parameters: {'learning_rate': 0.008419192690044127, 'n_estimators': 177, 'max_depth': 8, 'num_leaves': 64, 'min_child_samples': 16, 'subsample': 0.7916486569067794, 'colsample_bytree': 0.9273513414957818, 'reg_alpha': 0.9189727544001355, 'reg_lambda': 0.20912102029724422}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 01:59:47,088] Trial 5 finished with value: 0.7957567007720796 and parameters: {'learning_rate': 0.08222974786382906, 'n_estimators': 109, 'max_depth': 4, 'num_leaves': 49, 'min_child_samples': 69, 'subsample': 0.6074568982247042, 'colsample_bytree': 0.8687610637509477, 'reg_alpha': 0.885369895098288, 'reg_lambda': 0.9577247221743527}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 01:59:49,810] Trial 6 finished with value: 0.7980101688531793 and parameters: {'learning_rate': 0.008665249678717242, 'n_estimators': 827, 'max_depth': 9, 'num_leaves': 119, 'min_child_samples': 76, 'subsample': 0.7696395244730249, 'colsample_bytree': 0.9416351100970846, 'reg_alpha': 0.3764300753900268, 'reg_lambda': 0.17077233724998164}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 01:59:52,648] Trial 7 finished with value: 0.8002448057246877 and parameters: {'learning_rate': 0.0068447141692924655, 'n_estimators': 582, 'max_depth': 6, 'num_leaves': 130, 'min_child_samples': 29, 'subsample': 0.8170453099837354, 'colsample_bytree': 0.6132277349242958, 'reg_alpha': 0.6884014075769151, 'reg_lambda': 0.7116206009258015}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 01:59:57,694] Trial 8 finished with value: 0.8002448057246877 and parameters: {'learning_rate': 0.0015731816359662713, 'n_estimators': 867, 'max_depth': 8, 'num_leaves': 98, 'min_child_samples': 18, 'subsample': 0.9314242088973326, 'colsample_bytree': 0.9154242487548122, 'reg_alpha': 0.7039678671276763, 'reg_lambda': 0.7975357656526176}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 01:59:59,655] Trial 9 finished with value: 0.7968740192078337 and parameters: {'learning_rate': 0.0051112474463882495, 'n_estimators': 721, 'max_depth': 7, 'num_leaves': 28, 'min_child_samples': 81, 'subsample': 0.6109874263903939, 'colsample_bytree': 0.8872931025585883, 'reg_alpha': 0.533946603535603, 'reg_lambda': 0.6002334791562187}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 02:00:00,879] Trial 10 finished with value: 0.803603038101814 and parameters: {'learning_rate': 0.027399362623700484, 'n_estimators': 453, 'max_depth': 5, 'num_leaves': 20, 'min_child_samples': 94, 'subsample': 0.9833020255363686, 'colsample_bytree': 0.7506024199925968, 'reg_alpha': 0.0004475642450654238, 'reg_lambda': 0.34737455159911707}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 02:00:01,639] Trial 11 finished with value: 0.7856631724311092 and parameters: {'learning_rate': 0.030333961957594944, 'n_estimators': 300, 'max_depth': 6, 'num_leaves': 93, 'min_child_samples': 99, 'subsample': 0.8841543489257547, 'colsample_bytree': 0.6005132999463976, 'reg_alpha': 0.009386248545653064, 'reg_lambda': 0.4053468258832918}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 02:00:02,678] Trial 12 finished with value: 0.7912685958194714 and parameters: {'learning_rate': 0.0279881171100144, 'n_estimators': 443, 'max_depth': 3, 'num_leaves': 49, 'min_child_samples': 60, 'subsample': 0.874541052175528, 'colsample_bytree': 0.6796742664153957, 'reg_alpha': 0.2616671233193319, 'reg_lambda': 0.49438740616908716}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 02:00:04,996] Trial 13 finished with value: 0.8092398468394955 and parameters: {'learning_rate': 0.043977783818472796, 'n_estimators': 592, 'max_depth': 5, 'num_leaves': 82, 'min_child_samples': 38, 'subsample': 0.693595232832302, 'colsample_bytree': 0.8190711589671366, 'reg_alpha': 0.5123780223760301, 'reg_lambda': 0.3174704389400729}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 02:00:05,918] Trial 14 finished with value: 0.7991274872889335 and parameters: {'learning_rate': 0.016405594254786666, 'n_estimators': 252, 'max_depth': 10, 'num_leaves': 43, 'min_child_samples': 62, 'subsample': 0.8727586948767807, 'colsample_bytree': 0.6677501174396163, 'reg_alpha': 0.18814187363935525, 'reg_lambda': 0.5406237084106859}. Best is trial 1 with value: 0.812591802146758.\n",
      "[I 2025-04-06 02:00:07,885] Trial 15 finished with value: 0.813740505931831 and parameters: {'learning_rate': 0.05006158026995807, 'n_estimators': 369, 'max_depth': 7, 'num_leaves': 110, 'min_child_samples': 33, 'subsample': 0.7416325838946595, 'colsample_bytree': 0.7762786629808852, 'reg_alpha': 0.3720366322390498, 'reg_lambda': 0.9191901211821276}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:08,002] Trial 16 finished with value: 0.7867993220764548 and parameters: {'learning_rate': 0.015385762174565743, 'n_estimators': 34, 'max_depth': 5, 'num_leaves': 149, 'min_child_samples': 86, 'subsample': 0.8314748289946436, 'colsample_bytree': 0.7867017479237338, 'reg_alpha': 0.37506247312284663, 'reg_lambda': 0.888705485546832}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:11,873] Trial 17 finished with value: 0.7968740192078339 and parameters: {'learning_rate': 0.00268408327656151, 'n_estimators': 970, 'max_depth': 4, 'num_leaves': 117, 'min_child_samples': 34, 'subsample': 0.7443961482363906, 'colsample_bytree': 0.8186778861288727, 'reg_alpha': 0.14594852924156188, 'reg_lambda': 0.04175109160616186}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:13,685] Trial 18 finished with value: 0.8024982738057874 and parameters: {'learning_rate': 0.04983886314619333, 'n_estimators': 658, 'max_depth': 4, 'num_leaves': 111, 'min_child_samples': 50, 'subsample': 0.9910430215649612, 'colsample_bytree': 0.7469538709918695, 'reg_alpha': 0.35758198483285536, 'reg_lambda': 0.24301264730393085}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:15,954] Trial 19 finished with value: 0.8047329106772958 and parameters: {'learning_rate': 0.01619477822527487, 'n_estimators': 392, 'max_depth': 6, 'num_leaves': 83, 'min_child_samples': 26, 'subsample': 0.9341423072532893, 'colsample_bytree': 0.6777932154053719, 'reg_alpha': 0.09227415710470174, 'reg_lambda': 0.9968853147923368}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:17,926] Trial 20 finished with value: 0.8114870378507313 and parameters: {'learning_rate': 0.09551928649070537, 'n_estimators': 604, 'max_depth': 8, 'num_leaves': 139, 'min_child_samples': 70, 'subsample': 0.6444390316778608, 'colsample_bytree': 0.7779600789179123, 'reg_alpha': 0.2737680564049464, 'reg_lambda': 0.46869090847947315}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:19,828] Trial 21 finished with value: 0.8125980792166217 and parameters: {'learning_rate': 0.08125375233500641, 'n_estimators': 544, 'max_depth': 8, 'num_leaves': 148, 'min_child_samples': 69, 'subsample': 0.6472188530843985, 'colsample_bytree': 0.7932287831503738, 'reg_alpha': 0.2924514791059073, 'reg_lambda': 0.39958094427369273}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:21,331] Trial 22 finished with value: 0.8103571652752496 and parameters: {'learning_rate': 0.058020868280788264, 'n_estimators': 515, 'max_depth': 7, 'num_leaves': 150, 'min_child_samples': 87, 'subsample': 0.737943798979623, 'colsample_bytree': 0.8441969138834373, 'reg_alpha': 0.44341194310641663, 'reg_lambda': 0.33341292152292945}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:23,221] Trial 23 finished with value: 0.8069801016885318 and parameters: {'learning_rate': 0.04692811690100047, 'n_estimators': 506, 'max_depth': 9, 'num_leaves': 130, 'min_child_samples': 69, 'subsample': 0.6496624211757808, 'colsample_bytree': 0.7246296777176392, 'reg_alpha': 0.2958404710616568, 'reg_lambda': 0.42640716174791277}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:25,773] Trial 24 finished with value: 0.8125792480070304 and parameters: {'learning_rate': 0.03542535745203345, 'n_estimators': 678, 'max_depth': 8, 'num_leaves': 106, 'min_child_samples': 60, 'subsample': 0.8445893297062772, 'colsample_bytree': 0.7645531332667959, 'reg_alpha': 0.6054752542227306, 'reg_lambda': 0.12935944958705226}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:27,126] Trial 25 finished with value: 0.8081162513338773 and parameters: {'learning_rate': 0.06755493502933294, 'n_estimators': 370, 'max_depth': 10, 'num_leaves': 77, 'min_child_samples': 76, 'subsample': 0.6499366887628895, 'colsample_bytree': 0.7193159158478107, 'reg_alpha': 0.42823934371338684, 'reg_lambda': 0.5928940884697083}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:31,603] Trial 26 finished with value: 0.8058627832527776 and parameters: {'learning_rate': 0.0270986291129726, 'n_estimators': 925, 'max_depth': 7, 'num_leaves': 96, 'min_child_samples': 45, 'subsample': 0.7737933984241049, 'colsample_bytree': 0.8113250781886723, 'reg_alpha': 0.08012141474927602, 'reg_lambda': 0.29446362120017866}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:33,285] Trial 27 finished with value: 0.8013746783001695 and parameters: {'learning_rate': 0.019207353966626223, 'n_estimators': 541, 'max_depth': 6, 'num_leaves': 131, 'min_child_samples': 88, 'subsample': 0.9252501246085962, 'colsample_bytree': 0.6523040527957787, 'reg_alpha': 0.1437449759802393, 'reg_lambda': 0.8016961514268777}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:34,333] Trial 28 finished with value: 0.8036344234511331 and parameters: {'learning_rate': 0.040402167928131456, 'n_estimators': 214, 'max_depth': 9, 'num_leaves': 139, 'min_child_samples': 56, 'subsample': 0.7387615125770836, 'colsample_bytree': 0.8524473031645672, 'reg_alpha': 0.3224528615253128, 'reg_lambda': 0.4193279680663876}. Best is trial 15 with value: 0.813740505931831.\n",
      "[I 2025-04-06 02:00:37,254] Trial 29 finished with value: 0.8114870378507313 and parameters: {'learning_rate': 0.06558840092100339, 'n_estimators': 339, 'max_depth': 7, 'num_leaves': 74, 'min_child_samples': 12, 'subsample': 0.6804473013332019, 'colsample_bytree': 0.9662357685621539, 'reg_alpha': 0.2387277405745319, 'reg_lambda': 0.6214448014425895}. Best is trial 15 with value: 0.813740505931831.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params)\n",
    "    score = cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8731762065095399\n",
      "0.8770949720670391\n"
     ]
    }
   ],
   "source": [
    "best_model = LGBMClassifier(**study.best_params)\n",
    "best_model.fit(X, y)\n",
    "\n",
    "print(best_model.score(X, y))\n",
    "print(best_model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_pred)\n",
    "df_sub['Survived'] = y_pred\n",
    "df_sub.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
